{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import seaborn as sns\n",
    "\n",
    "# Añadir las claves (Yo las quito para evitar problemas con mi cuenta de desarrolador)\n",
    "consumer_key = \"n0zihT8RhgzbnoQoT02iLGFPp\"\n",
    "consumer_secret = \"Jv72TVss1NBHsDoTezNdybuW1ors0M28u0IHCqCgLzIO8hNKDJ\"\n",
    "access_token = \"1344609429543653377-9RC4xllEhCYOvYpKoF1dG4RO2sTVLT\"\n",
    "access_token_secret = \"QwVL3WjYmV6yECUTBUBZkRbhsvMoDd0jJ6lrCjaQzhKWQ\"\n",
    "\n",
    "#Para OAuth 1.0 (Objeto con mis credenciales)\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#Conexión a la API\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tarea 1\n",
    "\n",
    "Diseñar un script para descargar, mediante la función api.search(), los 500 últimos tweets (excluyendo los RT) y guardar el resultado en un dataframe, que tendrá 4 columnas con la siguiente información:\n",
    "\n",
    "    Fecha del tweet\n",
    "    Nombre del usuario que lo ha escrito\n",
    "    Texto completo del tweet\n",
    "    Número de retweets que ha tenido el tweet\n",
    "\n",
    " Los criterios de búsqueda serán:\n",
    "\n",
    "    Que contengan las palabras \"ONG\" o \"inmigrante\"\n",
    "    Que sean del día 28 de enero de 2021\n",
    "    Que estén escritos en castellano\n",
    "\n",
    "A partir del dataframe, generar una gráfica de barras que muestre los 5 usuarios que más tweets han escrito en el conjunto descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []        # Tabla a convertir en dataframe\n",
    "num_tweets = 500  # Número de tweets a buscar\n",
    "\n",
    "# Parámetros de la búsqueda que vamos ha realizar\n",
    "tweetsBuscados = tweepy.Cursor(api.search,\n",
    "                               q=\"ONG\" or \"inmigrante\",\n",
    "                               tweet_mode=\"extended\",\n",
    "                               lang=\"es\",\n",
    "                               since=\"2021-01-28\",\n",
    "                               until=\"2021-01-29\",\n",
    "                               excluded_replies = True,\n",
    "                               include_rts = False).items(num_tweets)\n",
    "\n",
    "for tweet in tweetsBuscados:\n",
    "    datos.append([tweet.created_at, tweet.user.screen_name, tweet.full_text, tweet.retweet_count])\n",
    "\n",
    "# Transformamos la tabla en un dataframe y lo mostramos por pantalla\n",
    "datos = pd.DataFrame(datos, columns = [\"Fecha\", \"Nombre_Usuario\", \"Tweet\", \"RTs\"])\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b91e2c34cf1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Recorremos el dataframe almacenando cada usuario en la lista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0musuarios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Nombre_Usuario\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datos' is not defined"
     ]
    }
   ],
   "source": [
    "# Creamos una lista que almacenará los usuarios\n",
    "usuarios = []\n",
    "\n",
    "# Recorremos el dataframe almacenando cada usuario en la lista\n",
    "for i in datos.index:\n",
    "    usuarios.append(datos[\"Nombre_Usuario\"][i])\n",
    "    \n",
    "# Creamos una colección que cuente las veces que aperece el usuario en el dataframe, es decir, el número de\n",
    "# veces que ha tuiteado sobre el tema\n",
    "n_tweets = collections.Counter(usuarios).most_common(5)\n",
    "\n",
    "# Guardamos cada dato de la colección en una lista separada para posteriormente graficar los resultados\n",
    "listaUsers = []\n",
    "listaTweets = []\n",
    "for usuario, tweets in n_tweets:\n",
    "    listaUsers.append(usuario)\n",
    "    listaTweets.append(tweets)\n",
    "print(listaUsers)\n",
    "print(listaTweets)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Ponemos una etiqueta al eje Y\n",
    "ax.set_ylabel(\"Número de Tweets\")\n",
    "# Ponemos una etiqueta al eje X\n",
    "ax.set_xlabel(\"Usuario\")\n",
    "# Ponemos los nombres de usuario en vertical para que quepan\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "# Sacamos la gráfica por pantalla\n",
    "sns.barplot(x=listaUsers, y=listaTweets,  edgecolor=\"black\", linewidth=1)\n",
    "plt.savefig(\"usuariosTuiteros.jpg\", bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tarea 2 (opcional)\n",
    "\n",
    "El script \"Tarea2.ipynb\" (está en la sección \"Otros recursos\") realiza, mediante streaming, una descarga de tweets y almacena, en un fichero csv, 4 campos (la fecha del tweet, el screen_name del autor, el texto del tweet y los hashtags).\n",
    "\n",
    "Modificarlo para que, además, recupere y almacene el nombre completo del usuario y su localización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self, api=None):\n",
    "        #super().__init__()\n",
    "        self.counter = 0\n",
    "        self.limit = 10\n",
    "    \n",
    "    def on_connect(self):\n",
    "        print(\"Conexión correcta!!!!\")\n",
    "             \n",
    "    def on_data(self, data):\n",
    "        \n",
    "        status = json.loads(data)\n",
    "        \n",
    "        ###### Este bloque es para recuperar, correctamente, el texto del tweet #################################\n",
    "        if 'text' in status:\n",
    "            text = status['text']\n",
    "        if 'extended_tweet' in status:\n",
    "            text = status['extended_tweet']['full_text']\n",
    "        if 'retweeted_status' in status:\n",
    "            status_RT = status['retweeted_status']\n",
    "            if 'text' in status_RT:\n",
    "                text = 'RT @' + status['retweeted_status']['user']['screen_name'] + status_RT['text']    \n",
    "                if 'extended_tweet' in status_RT:\n",
    "                    extended_RT = status_RT['extended_tweet']\n",
    "                    text = 'RT @' + status['retweeted_status']['user']['screen_name'] + extended_RT['full_text']\n",
    "        ###### Este bloque es para recuperar, correctamente, el texto del tweet #################################\n",
    "        \n",
    "        \n",
    "        ###### Para recuperar los hashtags que están dentro de una estructura de tipo diccionario #############\n",
    "        hashtags = []\n",
    "        for hashtag in status['entities']['hashtags']:\n",
    "            hashtags.append(hashtag['text'])\n",
    "        ###### Para recuperar los hashtags que están dentro de una estructura de tipo diccionario #############\n",
    "        \n",
    "        \n",
    "        #### Este bloque sirve para almacenar alguna información del tweet en un fichero csv\n",
    "        #### En este caso la fecha \"status['created_at']\",el screen_name del autor \"status['user']['screen_name']\",\n",
    "        #### el texto del tweet \"text.replace(\"\\n\", \"\")\" y los hashtags \"hashtags\"\n",
    "        #### Modificarlo para que también añada el nombre completo del autor y su localización\n",
    "        # status[\"user\"][\"name\"] --> Nombre completo del usuario\n",
    "        # status[\"user\"][\"location\"] --> Localización\n",
    "        # añadimos %s por cada variable añadida al fichero y \\t por cada separación de elementos\n",
    "        with open(\"Tarea2.csv\", \"a\", encoding='utf-8') as f:\n",
    "            f.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (status['created_at'],status['user']['screen_name'],status[\"user\"][\"name\"],\n",
    "                                              status[\"user\"][\"location\"],text.replace(\"\\n\", \"\"), hashtags))\n",
    "        \n",
    "        self.counter += 1\n",
    "        if self.counter < self.limit:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Error\", status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión correcta!!!!\n"
     ]
    }
   ],
   "source": [
    "listener = MiListener(api=tweepy.API(wait_on_rate_limit=True, wait_on_rate_limit_notify=True)) \n",
    "MiStreamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "MiStreamer.filter(track = ['immigrant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Nombre_Completo</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Jan 31 15:02:52 +0000 2021</td>\n",
       "      <td>orgdoctor1</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Kansas, USA</td>\n",
       "      <td>RT @stuartpstevensThe most dangerous immigrant...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Jan 31 15:02:52 +0000 2021</td>\n",
       "      <td>SarahPo77021908</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>None</td>\n",
       "      <td>@catturd2 @Pamsta67 I think Biden is great 😊 I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Jan 31 15:02:59 +0000 2021</td>\n",
       "      <td>MiamiPapers</td>\n",
       "      <td>Miami Secret Papers</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>RT @PnutBilly@HueyPNewton13 Which one is not l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Jan 31 15:03:03 +0000 2021</td>\n",
       "      <td>DashOh1</td>\n",
       "      <td>D.D.</td>\n",
       "      <td>Auburn, WA</td>\n",
       "      <td>@GaryGanjaGrows @thedgtalempress We can’t “tak...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Jan 31 15:03:06 +0000 2021</td>\n",
       "      <td>Akhgustavo</td>\n",
       "      <td>AbuAisha🇸🇴</td>\n",
       "      <td>None</td>\n",
       "      <td>@A__zak__ Yeah I believe they got Muhammad Kud...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Jan 31 15:03:06 +0000 2021</td>\n",
       "      <td>YNWA_Liverpool9</td>\n",
       "      <td>Bell</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>RT @jacobsoboroffTrump admin “separated far mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun Jan 31 15:03:14 +0000 2021</td>\n",
       "      <td>john51652772</td>\n",
       "      <td>john_homeless_student</td>\n",
       "      <td>London</td>\n",
       "      <td>@TerryCretin @SimonJonesNews @ShadiaED @Shadia...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sun Jan 31 15:03:21 +0000 2021</td>\n",
       "      <td>NeejaB</td>\n",
       "      <td>Neeja Bakshi</td>\n",
       "      <td>None</td>\n",
       "      <td>Grieving during COVID times. When you are seco...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun Jan 31 15:03:29 +0000 2021</td>\n",
       "      <td>KtbMoa</td>\n",
       "      <td>Ely Cheikh</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @jacobinmagThe arrest of Russian opposition...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun Jan 31 15:03:39 +0000 2021</td>\n",
       "      <td>freefilustine</td>\n",
       "      <td>Freedom and Justice Bee</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @santafeezThe Enduring Harms of Trump’s Mus...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Fecha            Autor          Nombre_Completo  \\\n",
       "0  Sun Jan 31 15:02:52 +0000 2021       orgdoctor1                  Barbara   \n",
       "1  Sun Jan 31 15:02:52 +0000 2021  SarahPo77021908                    Sarah   \n",
       "2  Sun Jan 31 15:02:59 +0000 2021      MiamiPapers      Miami Secret Papers   \n",
       "3  Sun Jan 31 15:03:03 +0000 2021          DashOh1                     D.D.   \n",
       "4  Sun Jan 31 15:03:06 +0000 2021       Akhgustavo               AbuAisha🇸🇴   \n",
       "5  Sun Jan 31 15:03:06 +0000 2021  YNWA_Liverpool9                     Bell   \n",
       "6  Sun Jan 31 15:03:14 +0000 2021     john51652772    john_homeless_student   \n",
       "7  Sun Jan 31 15:03:21 +0000 2021           NeejaB             Neeja Bakshi   \n",
       "8  Sun Jan 31 15:03:29 +0000 2021           KtbMoa               Ely Cheikh   \n",
       "9  Sun Jan 31 15:03:39 +0000 2021    freefilustine  Freedom and Justice Bee   \n",
       "\n",
       "            Location                                              Tweet  \\\n",
       "0        Kansas, USA  RT @stuartpstevensThe most dangerous immigrant...   \n",
       "1               None  @catturd2 @Pamsta67 I think Biden is great 😊 I...   \n",
       "2          Miami, FL  RT @PnutBilly@HueyPNewton13 Which one is not l...   \n",
       "3         Auburn, WA  @GaryGanjaGrows @thedgtalempress We can’t “tak...   \n",
       "4               None  @A__zak__ Yeah I believe they got Muhammad Kud...   \n",
       "5  Pennsylvania, USA  RT @jacobsoboroffTrump admin “separated far mo...   \n",
       "6             London  @TerryCretin @SimonJonesNews @ShadiaED @Shadia...   \n",
       "7               None  Grieving during COVID times. When you are seco...   \n",
       "8               None  RT @jacobinmagThe arrest of Russian opposition...   \n",
       "9               None  RT @santafeezThe Enduring Harms of Trump’s Mus...   \n",
       "\n",
       "  Hashtags  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  \n",
       "5       []  \n",
       "6       []  \n",
       "7       []  \n",
       "8       []  \n",
       "9       []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfStream = pd.read_csv('Tarea2.csv', sep='\\t', encoding = 'UTF-8', header = None)\n",
    "dfStream.columns = ['Fecha','Autor','Nombre_Completo','Location','Tweet','Hashtags']\n",
    "dfStream.shape\n",
    "dfStream"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
